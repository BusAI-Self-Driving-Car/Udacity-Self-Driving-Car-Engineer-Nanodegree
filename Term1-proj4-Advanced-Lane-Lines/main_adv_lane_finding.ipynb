{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToDo\n",
    "\n",
    "* ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding corners in calibration image 0\n",
      "... found\n",
      "\n",
      "Finding corners in calibration image 1\n",
      "... found\n",
      "\n",
      "Finding corners in calibration image 2\n",
      "... found\n",
      "\n",
      "Finding corners in calibration image 3\n",
      "    ... unsuccessful\n",
      "\n",
      "Finding corners in calibration image 4\n",
      "... found\n",
      "\n",
      "Finding corners in calibration image 5\n",
      "... found\n",
      "\n",
      "Finding corners in calibration image 6\n",
      "... found\n",
      "\n",
      "Finding corners in calibration image 7\n",
      "    ... unsuccessful\n",
      "\n",
      "Finding corners in calibration image 8\n",
      "... found\n",
      "\n",
      "Finding corners in calibration image 9\n",
      "... found\n",
      "\n",
      "Finding corners in calibration image 10\n",
      "... found\n",
      "\n",
      "Finding corners in calibration image 11\n",
      "... found\n",
      "\n",
      "Finding corners in calibration image 12\n",
      "... found\n",
      "\n",
      "Finding corners in calibration image 13\n",
      "... found\n",
      "\n",
      "Finding corners in calibration image 14\n",
      "... found\n",
      "\n",
      "Finding corners in calibration image 15\n",
      "    ... unsuccessful\n",
      "\n",
      "Finding corners in calibration image 16\n",
      "... found\n",
      "\n",
      "Finding corners in calibration image 17\n",
      "... found\n",
      "\n",
      "Finding corners in calibration image 18\n",
      "... found\n",
      "\n",
      "Finding corners in calibration image 19\n",
      "... found\n",
      "\n",
      "Calibrating camera ...\n",
      "camera matrix: [[  1.15396093e+03   0.00000000e+00   6.69705357e+02]\n",
      " [  0.00000000e+00   1.14802496e+03   3.85656234e+02]\n",
      " [  0.00000000e+00   0.00000000e+00   1.00000000e+00]]\n",
      "\n",
      "distortion coefficients: [[ -2.41017956e-01  -5.30721171e-02  -1.15810354e-03  -1.28318858e-04\n",
      "    2.67125300e-02]]\n",
      "Using already available cached calibration results.\n",
      "\n",
      "camera matrix: [[  1.15396093e+03   0.00000000e+00   6.69705357e+02]\n",
      " [  0.00000000e+00   1.14802496e+03   3.85656234e+02]\n",
      " [  0.00000000e+00   0.00000000e+00   1.00000000e+00]]\n",
      "\n",
      "distortion coefficients: [[ -2.41017956e-01  -5.30721171e-02  -1.15810354e-03  -1.28318858e-04\n",
      "    2.67125300e-02]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from camera_calibration import calibrate_camera, undistort_image\n",
    "from image_binarization import abs_sobel_thresh_x_or_y, mag_thresh, dir_threshold, hls_select\n",
    "from perspective_transformation import get_src_dst_vertices, get_perspective_transform, warp_image_to_top_down_view\n",
    "\n",
    "def process_frame(image, mtx, dist, perspective_M):\n",
    "    \n",
    "    # Gradient thresholding\n",
    "    ## Thresholding on x- or y-gradients\n",
    "    grad_x_binary = abs_sobel_thresh_x_or_y(image, orient='x', thresh_min=20, thresh_max=100)\n",
    "    grad_y_binary = abs_sobel_thresh_x_or_y(image, orient='y', thresh_min=20, thresh_max=100)\n",
    "\n",
    "    ## Thresholding on magnitude of gradient\n",
    "    mag_binary = mag_thresh(image, sobel_kernel=3, mag_thresh=(30, 100))\n",
    "\n",
    "    ## Thresholding on direction of gradient\n",
    "    dir_binary = dir_threshold(image, sobel_kernel=15, thresh=(0.7, 1.3))\n",
    "\n",
    "    ## Combine different gradient thresholding strategies\n",
    "    combined = np.zeros_like(mag_binary)\n",
    "    combined[((grad_x_binary==1) & (grad_y_binary==1)) | ((mag_binary==1) & (dir_binary==1))] = 1\n",
    "\n",
    "    ## Color thresholding\n",
    "    hls_binary = hls_select(image, thresh=(90, 255))\n",
    "\n",
    "    # Combine the threshold and gradient thresholding\n",
    "    combined_binary = np.zeros_like(grad_x_binary)\n",
    "    combined_binary[(grad_x_binary == 1) | (hls_binary == 1)] = 1    \n",
    "\n",
    "    img_size = (image.shape[1], image.shape[0])\n",
    "    top_down_binary = warp_image_to_top_down_view(combined_binary.astype(np.uint8), \n",
    "                                   img_size, \n",
    "                                   mtx, dist, perspective_M).astype(bool)\n",
    "    return top_down_binary\n",
    "\n",
    "\n",
    "def initialize():\n",
    "    # Calibrate camera\n",
    "    mtx, dist = calibrate_camera(use_calib_cache=True)\n",
    "    \n",
    "    # Perspective transform\n",
    "    test_image = cv2.cvtColor(cv2.imread('./test_images/straight_lines1.jpg'), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    img_size = (test_image.shape[1], test_image.shape[0])\n",
    "    src, dst = get_src_dst_vertices(img_size)\n",
    "    \n",
    "    img_undistorted = undistort_image(test_image, mtx, dist, plot_images=False)\n",
    "    _, perspective_M, perspective_M_inv = get_perspective_transform(img_undistorted, img_size, \n",
    "                                                                    mtx, dist, src, dst)\n",
    "    \n",
    "    return mtx, dist, perspective_M, perspective_M_inv\n",
    "    \n",
    "    \n",
    "def test_process_frame():\n",
    "    mtx, dist, perspective_M, perspective_M_inv = initialize()\n",
    "\n",
    "    # Read in an image\n",
    "    image = cv2.cvtColor(cv2.imread('./test_images/straight_lines2.jpg'), cv2.COLOR_BGR2RGB)\n",
    "    img_undistorted = undistort_image(image, mtx, dist, plot_images=False)\n",
    "    top_down_binary = process_frame(img_undistorted, mtx, dist, perspective_M)\n",
    "\n",
    "    # Plot the result\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(image)\n",
    "    ax1.set_title('Original Image', fontsize=50)\n",
    "    ax2.imshow(top_down_binary, cmap='gray')\n",
    "    ax2.set_title('Undistorted and Warped Image', fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    \n",
    "\n",
    "#test_process_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class window:\n",
    "    def __init__(self, x_low, x_high, y_low, y_high):\n",
    "        self.x_low = np.int32(x_low)\n",
    "        self.x_high = np.int32(x_high)\n",
    "        self.y_low = np.int32(y_low)\n",
    "        self.y_high = np.int32(y_high)\n",
    "\n",
    "def get_lane_indices(nonzero_indices, window_left, window_right):\n",
    "    \n",
    "    nonzeroy = np.array(nonzero_indices[0])\n",
    "    nonzerox = np.array(nonzero_indices[1])\n",
    "    \n",
    "    left_lane_inds = ((nonzeroy >= window_left.y_low) & (nonzeroy < window_left.y_high) & \n",
    "                      (nonzerox >= window_left.x_low) & (nonzerox < window_left.x_high)).nonzero()[0]\n",
    "    \n",
    "    right_lane_inds = ((nonzeroy >= window_right.y_low) & (nonzeroy < window_right.y_high) & \n",
    "                       (nonzerox >= window_right.x_low) & (nonzerox < window_right.x_high)).nonzero()[0]\n",
    "    \n",
    "    return left_lane_inds, right_lane_inds\n",
    "    \n",
    "# Extract left and right line pixel positions\n",
    "def get_lane_pixel_positions(nonzero_indices, left_lane_inds, right_lane_inds):\n",
    "    nonzeroy = np.array(nonzero_indices[0])\n",
    "    nonzerox = np.array(nonzero_indices[1])\n",
    "    \n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    return leftx, lefty, rightx, righty\n",
    "\n",
    "def get_line_fits(binary_warped, leftx, lefty, rightx, righty):\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    return left_fit, right_fit\n",
    "\n",
    "def get_x_y_for_plotting(binary_warped, left_fit, right_fit):\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    \n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    return ploty, left_fitx, right_fitx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def track_lane_lines(binary_warped, left_fit, right_fit):\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    out_img = (np.dstack((binary_warped, binary_warped, binary_warped))*255).astype(np.uint8)\n",
    "            \n",
    "    margin = 100  # dict_config_params['x_margin']\n",
    "    x_left = left_fit[0] * (nonzeroy**2) + left_fit[1] * nonzeroy + left_fit[2]\n",
    "    x_right = right_fit[0] * (nonzeroy**2) + right_fit[1] * nonzeroy + right_fit[2]\n",
    "        \n",
    "    w_left = window(x_left - margin, x_left + margin, nonzeroy.min(), nonzeroy.max()) \n",
    "    w_right = window(x_right - margin, x_right + margin, nonzeroy.min(), nonzeroy.max()) \n",
    "    \n",
    "    left_lane_inds, right_lane_inds = get_lane_indices(nonzero, w_left, w_right)\n",
    "    leftx, lefty, rightx, righty = get_lane_pixel_positions(nonzero, left_lane_inds, right_lane_inds)\n",
    "    \n",
    "    left_fit, right_fit = get_line_fits(binary_warped, leftx, lefty, rightx, righty)\n",
    "    ploty, left_fitx, right_fitx = get_x_y_for_plotting(binary_warped, left_fit, right_fit)\n",
    "    \n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    \n",
    "    ## Draw search windows for the left and right lane lines\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    \n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_window_left_line = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_window_right_line = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                                  ploty])))])\n",
    "    left_window_pts = np.hstack((left_window_left_line, left_window_right_line))\n",
    "    \n",
    "    right_window_left_line = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_window_right_line = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                                  ploty])))])\n",
    "    right_window_pts = np.hstack((right_window_left_line, right_window_right_line))\n",
    "    \n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_window_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_window_pts]), (0,255, 0))\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "\n",
    "    return result, left_fitx, right_fitx, ploty\n",
    "    \n",
    "\n",
    "def detect_lane_lines(binary_warped, plot_image=False):\n",
    "    \n",
    "    #print(\"binary_warped.shape = {}\".format(binary_warped.shape))\n",
    "    print()\n",
    "    \n",
    "    out_img = (np.dstack((binary_warped, binary_warped, binary_warped))*255).astype(np.uint8)\n",
    "        \n",
    "    # Assuming you have created a warped binary image called \"binary_warped\"\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[np.int(binary_warped.shape[0]/2):,:], axis=0)\n",
    "    #print(\"histogram.shape = {}\".format(histogram.shape))\n",
    "    #print()        \n",
    "    \n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    n_windows = 9\n",
    "    \n",
    "    # Set height of windows\n",
    "    window_height = np.int(binary_warped.shape[0]/n_windows)\n",
    "    \n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    \n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    \n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    \n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for n_window in range(n_windows):\n",
    "        \n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        y_low = binary_warped.shape[0] - (n_window + 1) * window_height\n",
    "        y_high = binary_warped.shape[0] - n_window * window_height\n",
    "        \n",
    "        xleft_low = leftx_current - margin\n",
    "        xleft_high = leftx_current + margin\n",
    "        \n",
    "        xright_low = rightx_current - margin\n",
    "        xright_high = rightx_current + margin\n",
    "        \n",
    "        w_left = window(xleft_low, xleft_high, y_low, y_high) \n",
    "        w_right = window(xright_low, xright_high, y_low, y_high) \n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        # print(\"left_window = ({}, {}), ({}, {})\".format(xleft_low, y_low, xleft_high, y_high))\n",
    "        if False: #plot_image:\n",
    "            cv2.rectangle(out_img,\n",
    "                          (xleft_low, y_low), (xleft_high, y_high), \n",
    "                          (0,255,0), 5) \n",
    "            cv2.rectangle(out_img,\n",
    "                          (xright_low, y_low), (xright_high, y_high), \n",
    "                          (0,255,0), 5)     \n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds, good_right_inds = get_lane_indices(nonzero, w_left, w_right)\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        # Else the next windows retain the x-coords. of the previous (below) one\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    print()\n",
    "    # Concatenate the arrays of indices\n",
    "    print(\"len(left_lane_inds) = {}\".format(len(left_lane_inds)))\n",
    "    print(\"len(left_lane_inds[0]) = {}\".format(len(left_lane_inds[0])))\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    print(\"concat. len(left_lane_inds) = {}\".format(len(left_lane_inds)))\n",
    "    print()\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    leftx, lefty, rightx, righty = get_lane_pixel_positions(nonzero, left_lane_inds, right_lane_inds)\n",
    "    \n",
    "    left_fit, right_fit = get_line_fits(binary_warped, leftx, lefty, rightx, righty)\n",
    "    ploty, left_fitx, right_fitx = get_x_y_for_plotting(binary_warped, left_fit, right_fit)\n",
    "    \n",
    "    # Color the left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    if plot_image:        \n",
    "        plt.imshow(out_img)\n",
    "        plt.plot(left_fitx, ploty, color='yellow')\n",
    "        plt.plot(right_fitx, ploty, color='yellow')\n",
    "        plt.xlim(0, 1280)\n",
    "        plt.ylim(720, 0)\n",
    "    \n",
    "    return out_img, left_fit, right_fit, left_fitx, right_fitx, ploty\n",
    "\n",
    "def test_detect_lane_lines():\n",
    "    mtx, dist, perspective_M, perspective_M_inv = initialize()\n",
    "\n",
    "    # Read in an image\n",
    "    image = cv2.cvtColor(cv2.imread('./test_images/straight_lines2.jpg'), cv2.COLOR_BGR2RGB)\n",
    "    img_undistorted = undistort_image(image, mtx, dist, plot_images=False)\n",
    "    top_down_binary = process_frame(img_undistorted, mtx, dist, perspective_M)\n",
    "    \n",
    "    print(\"top_down_binary.shape = {}\".format(top_down_binary.shape))\n",
    "    out_image, left_fit, right_fit, left_fitx, right_fitx, ploty = detect_lane_lines(top_down_binary, \n",
    "                                                                                     plot_image=True)\n",
    "\n",
    "    print(\"left_fit: {}\".format(left_fit))\n",
    "    print(\"right_fit: {}\".format(right_fit))\n",
    "    \n",
    "# test_detect_lane_lines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset global\n",
    "num_frames_processed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using already available cached calibration results.\n",
      "\n",
      "\n",
      "\n",
      "len(left_lane_inds) = 9\n",
      "len(left_lane_inds[0]) = 2190\n",
      "concat. len(left_lane_inds) = 31238\n",
      "\n",
      "left_fit: [ -2.02462902e-04   2.73635423e-01   2.66714955e+02]\n",
      "num_frames_processed: 1\n",
      "[MoviePy] >>>> Building video out_project_video.mp4\n",
      "[MoviePy] Writing video out_project_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/51 [00:00<00:10,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames_processed: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 2/51 [00:00<00:10,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames_processed: 3\n",
      "num_frames_processed: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/51 [00:00<00:09,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames_processed: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/51 [00:01<00:09,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames_processed: 6\n",
      "num_frames_processed: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/51 [00:01<00:08,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames_processed: 8\n",
      "num_frames_processed: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 9/51 [00:01<00:08,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames_processed: 10\n",
      "num_frames_processed: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/51 [00:02<00:08,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames_processed: 12\n",
      "num_frames_processed: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 13/51 [00:02<00:07,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames_processed: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 14/51 [00:02<00:07,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames_processed: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 15/51 [00:03<00:07,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames_processed: 16\n",
      "num_frames_processed: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 17/51 [00:03<00:06,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames_processed: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 19/51 [00:03<00:06,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames_processed: 19\n",
      "num_frames_processed: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 20/51 [00:04<00:06,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames_processed: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 21/51 [00:04<00:06,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames_processed: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 23/51 [00:04<00:05,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames_processed: 23\n",
      "num_frames_processed: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 25/51 [00:05<00:05,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames_processed: 25\n",
      "num_frames_processed: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 27/51 [00:05<00:04,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames_processed: 27\n",
      "num_frames_processed: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 29/51 [00:05<00:04,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames_processed: 29\n",
      "num_frames_processed: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 31/51 [00:06<00:03,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames_processed: 31\n",
      "num_frames_processed: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 33/51 [00:06<00:03,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames_processed: 33\n",
      "num_frames_processed: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 35/51 [00:06<00:03,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames_processed: 35\n",
      "num_frames_processed: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 37/51 [00:07<00:02,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames_processed: 37\n",
      "num_frames_processed: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 39/51 [00:07<00:02,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames_processed: 39\n",
      "num_frames_processed: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 40/51 [00:07<00:02,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames_processed: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 42/51 [00:08<00:01,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames_processed: 42\n",
      "num_frames_processed: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 44/51 [00:08<00:01,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames_processed: 44\n",
      "num_frames_processed: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 46/51 [00:08<00:00,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames_processed: 46\n",
      "num_frames_processed: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 47/51 [00:09<00:00,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames_processed: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 49/51 [00:09<00:00,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames_processed: 49\n",
      "num_frames_processed: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 50/51 [00:09<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames_processed: 51\n",
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: out_project_video.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Video\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "from lane_lines import Line\n",
    "\n",
    "def get_lane_line_curvatures(left_fitx, right_fitx, ploty):\n",
    "    \n",
    "    y_eval = np.max(ploty)\n",
    "\n",
    "    y_meter_per_pixel = dict_config_params['y_meter_per_pixel']\n",
    "    x_meter_per_pixel = dict_config_params['x_meter_per_pixel']\n",
    "\n",
    "    # Fit polynomials to x,y in world space\n",
    "    left_fit = np.polyfit(ploty * y_meter_per_pixel, left_fitx * x_meter_per_pixel, 2)\n",
    "    right_fit = np.polyfit(ploty * y_meter_per_pixel, right_fitx * x_meter_per_pixel, 2)\n",
    "    \n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = (((1 + (2 * left_fit[0] * y_eval * y_meter_per_pixel + left_fit[1])**2)**1.5) / \n",
    "                        np.absolute(2*left_fit[0]))\n",
    "\n",
    "    right_curverad = (((1 + (2 * right_fit[0] * y_eval * y_meter_per_pixel + right_fit[1])**2)**1.5) / \n",
    "                        np.absolute(2*right_fit[0]))\n",
    "    \n",
    "    return left_curverad, right_curverad\n",
    "\n",
    "def project_lane_lines_to_road(frame_undistorted, top_down_binary,\n",
    "                               left_fitx, right_fitx, ploty, perspective_M_inv):\n",
    "    \n",
    "    if True:\n",
    "        img_size = (top_down_binary.shape[1], top_down_binary.shape[0])\n",
    "        warped = cv2.warpPerspective(top_down_binary, perspective_M_inv, img_size, flags=cv2.INTER_LINEAR)    \n",
    "        return warped\n",
    "    \n",
    "    # Create an image to draw the lines on\n",
    "    color_warp = np.zeros_like(frame_undistorted).astype(np.uint8)\n",
    "    \n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, perspective_M_inv, (color_warp.shape[1], color_warp.shape[0])) \n",
    "    \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(frame_undistorted, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def process_video_frame(frame):\n",
    "    # NOTE: output should be a color image (3 channel) for processing video below    \n",
    "    global num_frames_processed    \n",
    "    global mtx, dist, perspective_M, perspective_M_inv\n",
    "    global left_fit, right_fit, left_fitx, right_fitx\n",
    "    #global line_left, line_right\n",
    "    \n",
    "    frame_undistorted = undistort_image(frame, mtx, dist, plot_images=False)\n",
    "    top_down_binary = process_frame(frame_undistorted, mtx, dist, perspective_M)\n",
    "    \n",
    "    out_img = None\n",
    "    ploty = None\n",
    "    if num_frames_processed==0:        \n",
    "        out_img, left_fit, right_fit, left_fitx, right_fitx, ploty = detect_lane_lines(top_down_binary, \n",
    "                                                                                       plot_image=False) \n",
    "        print(\"left_fit: {}\".format(left_fit))\n",
    "    else:        \n",
    "        out_img, left_fitx, right_fitx, ploty = track_lane_lines(top_down_binary, left_fit, right_fit)\n",
    "    \n",
    "    num_frames_processed += 1\n",
    "    # print(\"num_frames_processed: {}\".format(num_frames_processed))\n",
    "        \n",
    "    img_lines_on_road = project_lane_lines_to_road(frame_undistorted, out_img,\n",
    "                                                   left_fitx, right_fitx, ploty, perspective_M_inv)\n",
    "    \n",
    "    left_curverad, right_curverad = get_lane_line_curvatures(left_fitx, right_fitx, ploty)\n",
    "    # print(\"left_curverad, right_curverad = {} m, {} m\".format(left_curverad, right_curverad))\n",
    "\n",
    "    return img_lines_on_road\n",
    "    \n",
    "    \n",
    "# Globals\n",
    "left_fit, right_fit, left_fitx, right_fitx = None, None, None, None\n",
    "mtx, dist, perspective_M, perspective_M_inv = None, None, None, None\n",
    "line_left = None\n",
    "line_right = None\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ## Config parameters\n",
    "    dict_config_params = {}\n",
    "\n",
    "    # Data I/O\n",
    "    dict_config_params['x_margin'] = 100\n",
    "\n",
    "    # Lane radius-of-curvature calculations\n",
    "    dict_config_params['y_meter_per_pixel'] = 30/720 # meters per pixel in y dimension\n",
    "    dict_config_params['x_meter_per_pixel'] = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    mtx, dist, perspective_M, perspective_M_inv = initialize()\n",
    "    line_left = Line()\n",
    "    line_right = Line()\n",
    "    \n",
    "    ## secs. 38--43 are difficult\n",
    "    clip1 = VideoFileClip(\"project_video.mp4\").subclip(0,2)\n",
    "    # clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "    clip = clip1.fl_image(process_video_frame)\n",
    "    clip.write_videofile(\"out_project_video.mp4\", audio=False)\n",
    "\n",
    "    # Reset global\n",
    "    num_frames_processed = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
